% !TEX root = ../document.tex

\chapter{Ermittlung des optischen Flusses}

Die wahrgenommene Bewegung hervorgerufen durch zwei Bilder in welcher die enthaltenen Objekte sich relativ zu einander Bewegen zu scheinen wird als \name{optischer Fluss}(zu engl. \name{Optical Flow}) bezeichnet. % TODO Zitat aus Modern AI, S. 939 unten.
Der optische Fluss kann durch ein Vektorfeld betrachtet werden, wobei die Vektoren jeweils die relative Bewegung des betrachteten Punktes darstellen.
Die Bewegung eines Objektes innerhalb zweier Bilder lässt sich durch

\begin{equation}
I(x, y, t) = I(x + \Delta x, y + \Delta y, t + \Delta t)
\label{eq:optical_flow}
\end{equation}

darstellen.
Hier stellen $x$ und $y$ jeweils die Koordinaten und $t$ die Helligkeit des Objektes dar.
Durch die Ermittlung der Differenzen lässt sich so die Bewegung ermitteln.
Wird diese Bewegung für jeden Pixel innerhalb zweier Bilder ermitteln, lässt sich so ein Vektorfeld für die Bewegung der einzelnen Objekte innerhalb eines Bildes darstellen.
Inspiriert durch diesen Ansatz scheint es naheliegend ihn auf planare Mechanismen anzuwenden um so aus einer Videoaufnahme, oder mehrerer Bildaufnahmen eines Mechanismus diesen synthetisieren zu können.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{gfx/ai_modern_approach_optical_flow.png}
    \caption{Hier werden zwei Bilder einer Bildsequenz gezeigt. Das dritte Bild zeigt das Vektorfeld an, welches die Bewegung der einzelnen Pixel im nächsten Bild vermutet~\cite[[S.~941]{Russell2010, Brox2009}.}
    \label{fig:ai_modern_approach_optical_flow}
\end{figure}

% Hier ein Bild von Thomas Brox scheint angebracht. (Modern AI S. 941)

\section{Optischer Fluss nach Lucas-Kanade}\label{ch:lucas_kanade}

Einen Vorschlag einer nutzbaren Implementation des optischen Flusses wurde von Lucas und Kanade bereits 1981 vorgeschlagen~\cite{Lucas1981}.

Der vorgeschlagene Ansatz trifft im vorherein jedoch mehrere Annahmen.
Die erste Annahme ist, dass die Bewegung nicht sehr groß ist.
Zu schnelle Bewegungen können durch diesen Ansatz wahrscheinlich nicht, oder nur schlecht erkannt werden.
Eine weitere Annahme ist, dass die zu untersuchende Bildsequenz in Graustufen immernoch nutzbar ist.
Es werden in dieser Methode die Helligkeitswerte der Pixel untersucht, sodass eine Szene welche in einer solchen Darstellung keine zu erkennende Bewegung hat entsprechend keine sinnvollen Ergebnisse verspricht.

Die Überlegung die in diesem Algorithmus verfolgt wird ist, dass für einen Pixel sich die Helligkeit genau dann verändert, wenn sich das zugrundeliegende Objekt bewegt hat.
Die Bewegung sollte durch einen Abgleich mit Benachbarten Pixeln gefunden werden indem der entsprechende Fehler minimiert wird der durch eine Bewegung erzeugt wird.
Wird das erste Bild für die entsprechenden Pixelwerte als eine Funktion $F(x)$ und die Pixelwerte des zweiten Bildes entsprechend als $G(x)$ beschrieben, so wird also jener Vektor gesucht, welcher den Fehler zwischen diesen beiden Funktionen minimiert.
Beschreiben diese Funktionen stattdessen Regionen auf entsprechenden Bildern, so kann der Vektor gesucht werden, welcher für die Bewegung dieser Regionen innerhalb der Bilder den geringsten Fehler ausschreibt.
Auf diese Weise kann versucht werden die Bewegung einzelner Objekte zu verfolgen.

Zunächst ist die Größe der Regionen unbekannt, deshalb wird ein pyramidischer Ansatz genutzt werden.
Das bedeutet, dass um eine Region von Interesse mehrere Regionen festgelegt werden, für welche der Fehler entsprechend berechnet wird.
Diese Fehler können dann verglichen werden und die passende Region wird genutzt um die Verschiebung des Punktes innerhalb des Bildes zu beschreiben.
Anhand dieses Ansatzes kann die ungefähre Größe des sich bewegenden Objektes untersucht werden.
Diese Implementation wird durch Jean-Yves Bouget beschrieben~\cite{Bouguet2000}.

Was für eine Nutzung nun noch fehlt ist die Festlegung der entsprechenden Regionen von Interesse.
Hierfür wird ein Algorithmus genutzt, welcher in einem Bild interessante Punkte anhand von Kantenerkennung identifiziert.
Entwickelt wurde dieser von J. Shi und C. Tomasi~\cite{Shi1994} und wird im nachfolgenden genutzt um die Menge der zu verfolgenden Punkte zu bestimmen.

\subsection{Implementation des Lucas-Kanade Algorithmus}

Um diesen Algorithmus in die nun bestehende Struktur zu implementieren, wird für die \lstinline{Group} Klasse eine weitere Eigenschaft definiert.
Diese Eigenschaft verweist auf ein Objekt der \lstinline{LucasKanade} Klasse.
Objekte der \lstinline{LucasKanade} Klasse enthalten wiederrum alle Parameter welche für die Implementation der Algorithmen notwendig sind.

Die Funktionen zur Bestimmung interessanter Punkte und dessen Verfolgung wird von \name{opencv.js} bezogen~\cite{OpenCV2021}.
\name{opencv}\footnote{\name{opencv} ist eine Abkürzung für Open Computer Vision.} ist eine Sammlung zumeist optimierter Funktionen im Bereich der Bildverarbeitung und des Maschniellen sehens.
Implementiert ist \name{opencv} in \name{C++}.
Es gibt jedoch Unterstüzung für eine Vielzahl von anderen Programmiersprachen, wie zum Beispiel \name{Python}, \name{Java} und \name{JavaScript}.

Für \name{JavaScript} wird das globale \lstinline{cv} Objekt genutzt um auf dessen Funktionen zuzugreifen.
Für die Bestimmung von vermeintlich sinnvollen Regionen zur Verfolgung wird die \lstinline{cv.goodFeaturesToTrack} Funktion verwendet.
Diese implementiert den Shi-Tomasi Algorithmus.
Als Parameter übergeben werden hier ein in Graustufen konvertiertes Bild, eine \lstinline{cv.Mat} Objekt in welchem die Ergebnisse gespeichert werden, die maximale Anzahl der Punkte welche zur Verfolgung gesucht werden, die minimale Qualität einer Kante\footnote{Die Qualität einer Kante wird hier ins Verhältnis zur Kante mit bester Qualität gestellt. Die Qualität einer hier genutzten Kante berechnet sich durch \lstinline{cv.cornerMinEigenVal}, worauf hier jedoch nicht weiter eingegangen wird. Mehr Information kann unter \aka{https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html\#ga3dbce297c1feb859ee36707e1003e0a8} gefunden werden.},
der minimale euklidische Abstand der Punkte zueinander.
Des weiteren können hier spezielle Regionen von Interesse übergeben werden und die durchschnittliche Größe der Blöcke welche bei der Berechnung genutzt werden.

Nach der Bestimmung der zu verfolgenden Punkte wird versucht diese durch \lstinline{cv.calcOpticalFlowPyrLK} zu verfolgen.
Die \lstinline{calcOpticalFlowPyrLK} Funktion benötigt als Parameter zunächst die beiden Bilder in zeitlicher Abfolge.
Der dritte Parameter sind die Punkte welche verfolgt werden sollen und der vierte Parameter ist das \lstinline{cv.Mat} Objekt welcher die berechnet Punkte enthalten wird.
Alles weitere sind Parameter zum Einstellen des Algorithmus, wie etwa der Status, einem Objekt zur Fehlerbehandlung, der Größe der Fenster für den pyramidischen Ablauf und die Anzahl der Iterationen von den im Verlauf der Berechnung größer werdenen Regionen.
Abschließend wird dem Algorithmus ein \lstinline{criteria} Parameter übergeben, welcher eine Abbruchbedingung für die iterative Suche darstellt.
Ein Abbruch findet dann statt, wenn eine maximale Anzahl von Iterationen stattfand, oder die Bewegung unterhalb eines bestimmten Wertes vermutet wird.

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \includegraphics[width=\textwidth]{gfx/lucas_kanade_simple.png}
        \caption{Versuch: \name{gruppe3\_1.html}. Hier wird gezeigt welche Punkte durch die \lstinline{cv.goodFeaturesToTrack} bei einem \name{mec2} Modell ermittelt werden.}\label{fig:gruppe3_1}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \includegraphics[width=\textwidth]{gfx/lucas_kanade_history.png}
        \caption{Versuch: \name{gruppe3\_2.html}. Durch die \lstinline{cv.calcOpticalFlowPyrLK} Funktion werden die Kanten über die Bildsequenz hinweg verfolgt.}\label{fig:gruppe3_2}
    \end{subfigure}
    \label{fig:gruppe_3_1_2}
\end{figure}

Die in der \lstinline{LucasKanade} Klasse definierte \lstinline{step} Funktion ist in Listing~\ref{lst:LucasKanade_step} abgebildet.

\begin{lstlisting}[language=JavaScript, caption={Implementation der \lstinline{step} Funktion der \lstinline{LucasKanade} Klasse}\label{lst:LucasKanade_step}]
step(frame) {
    if (!this.first_indicator) {
        this.goodFeaturesToTrack(frame);
        this.first_indicator = true;
    }

    cv.cvtColor(frame, this.frameGray, cv.COLOR_RGBA2GRAY);
    this.calcOpticalFlowPyrLK();
    const points = this.getPoints();

    this.frameGray.copyTo(this.oldGray);
    this.p0 = new cv.Mat(points.length, 1, cv.CV_32FC2);
    for (let i = 0; i < points.length; i++) {
        this.p0.data32F[i * 2] = points[i].x;
        this.p0.data32F[i * 2 + 1] = points[i].y;
    }

    return points;
}
\end{lstlisting}

Hier wird mittels der \lstinline{first_indicator} Eigenschaft geprüft, ob es sich um den ersten Aufruf handelt.
Wenn dies der Fall ist müssen die Regionen definiert werden, welche im Anschluss auf Bewegung untersucht werden sollen.
Dies soll jedoch nur einmal am Anfang geschehen, damit die Reihenfolge der gefundenen Punkte konsistenz bleibt.
Außerdem ist nicht sichergestellt, dass die vorgeschlagenen Regionen bei Veränderungen im Bild die selben bleiben.
Die gefundenen Punkte werden im \lstinline{LucasKanade} Objekt entsprechend gespeichert.
Nachdem das Bild in Graustufen übersetzt wurde wird es in der \lstinline{calcOpticalFlowPyrLK} Funktion genutzt um die entsprechend neuen Koordinaten der Punkte zu ermitteln.
Diese Punkte werden dann in einer \lstinline{points} Liste gespeichert, welche die zuletzt ermittelten Koordinaten enthält.
Daraufhin wird das \lstinline{oldGray} Bild überschrieben, damit es bei der nächsten Iteration entsprechend als erstes Bild dienen kann.
Ebenso wird \lstinline{p0} für die nächste Iteration auf die zuletzt ermittelten Koordinaten gesetzt.

Der Rückgabewert dieser Funktion ist die \lstinline{points} Liste.
Aufgerufen wird diese Funktion durch die \lstinline{lucasKanade} Funktion des \lstinline{group} Objektes.
Dieses ermittelt die Bildinformation von \lstinline{cnv1} durch \lstinline{cv.imread}, welches ein \lstinline{cv.Mat} Objekt zurückgibt.
Daraufhin wird die in Kapitel~\ref{ch:vergleich_verlauf_randpunkte} bereits angedeutete Funktion \lstinline{addPoints} genutzt um die nun für die nächste Iteration ermittelten Koordinaten der Punkte der Liste an Punkten hinzuzufügen.

Diese Punkte haben augenscheinlich eine sehr viel geringere Varianz als die Ansätze aus Kapitel~\ref{ch:infoerhalt_aus_abgleich_bilder}.
Allerdings wird hier zunächst nicht näher darauf eingegangen ob diese Punkte nun dazu genutzt werden können um auf die Drehpunkte zu schließen.
Darauf wird stattdessen in Kapitel~\ref{ch:ermittlung_momentanpol} eingegangen.

\section{Andere Methoden}

\subsection{Optischer Fluss nach Farneback}

Bei der Ermittlung des optischen Flusses wird zwischen dichtem und spärlichen optischen Fluss unterschieden\footnote{Englisch \textit{sparse and dense optical flow}.}.
Während der spärliche optische Fluss einzelne Regionen von Interesse im Bild verfolgt und entsprechend dessen Bewegung nachvollzieht, ist der Anspruch von Algorithmen zur Berechnung von dichten optischem Fluss die Berechnung der Bewegung jedes einzelnen Pixels.
Während ich auf die Implementation nicht weiter eingehen möchte, da dieser Ansatz wegen augenscheinlich zu großen Varianzen nicht weiter verfolgt wurde, verdient dieser dennoch eine Erwähnung.
Die Implementation wurde wenig optimiert, der entsprechende Test kann jedoch unter \name{src/gruppe/gruppe2\_1.html} eingesehen werden.

Zu erwarten wäre für ein sich um einen festen Punkt drehendes Glied, dass alle Vektoren zur Bestimmung der Bewegung den selben Einheitsvektor haben.
Der entsprechende Betrag des Vektors sollte linear mit Abstand zum Drehpunkt zunehmen.
Diese Information sollte dann genutzt werden können um die Pole der ebenen Bewegung zu ermitteln.

Des Weiteren hätten die Glieder durch den Verlauf der gemessenen Geschwindigkeiten leicht unterscheidbar gewesen sein sollen.
Da jedoch die Ungenauigkeiten hier zu groß zu sein scheinen fällt die Implementation entsprechend schwierig und wird hier nicht weiter Gegenstand sein.

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \includegraphics[width=\textwidth]{gfx/farneback_okay.png}
        \label{fig:gruppe2_1_okay}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \includegraphics[width=\textwidth]{gfx/farneback_bad.png}
        \label{fig:gruppe2_1_bad}
    \end{subfigure}
    \caption{Versuch: \name{gruppe2\_1.html}. Hier wird der Versuch mit dem optischen Fluss nach Farneback versucht. Die Farben stellen die vorausgesagte Richtung der entsprechenden Pixel dar. Auf dem ersten Bild scheinen diese noch relativ eindeutig zu sein. Es zeigt sich jedoch, dass vorallem für etwas schnellere Bewegungen diese Berechnungen sehr ungenau werden und starke Streuungen zeigen. Eine sinnvolle Nutzung bedarf entsprechend tieferer Analyse.}\label{fig:gruppe2_1_bad}
    \label{fig:gruppe_2_1}
\end{figure}

\subsection{Ermittlung von Bewegung durch maschinelles Lernen.}

Eine weitere Erwähnung verdienen modernere Ansätze zur Ermittlung des optischen Flusses.
Diese Methoden basieren zumeist auf den Grundsätzen des maschinellen Lernens.
Sie versprechen eine höhere Genauigkeit welche entsprechend dazu genutzt werden könnte die Pole der ebenen Bewegung zu finden.
Solche Ansätze versprechen zum einen die Segmentierung einzelner Objekte durch die Verfolgung der Trajektorien der Punkte~\cite{Ochs2014, Keuper2015}.
Diese Segmentierungen könnten dann im einzelnen analysiert werden, was die Problemstellung von Kapitel~\ref{ch:gruppierung_von_datenpunkten} darstellen wird.

Auch für die Ermittlung des Vektorfeldes wurden Neuronale Netze entwickelt, welche eine höhere Genauigkeit und weniger Streuung der Ergebnisse versprechen.
\name{FlowNet}~\cite{Fischer2015} ist ein \textit{Convolutional Neural Network}\footnote{Zu deutsch in etwa \textit{Faltendes neurales Netwerk}.}, welches durch automatisiert erstellte Trainingsdaten trainiert wurde.
Es wurden hierfür beliebige Hintergründe verwendet auf denen dann Bilder von Stühlen platziert wurden.
Diese Stühle wurden dann für das Training entsprechend ein wenig versetzt, damit das neurale Netz mit diesen vorgegebenen \textit{Ground Truth} Werten trainiert werden konnte.
Es muss hierbei berücksichtigt werden, dass das neurale Netz nicht durch die Objekte, sondern dessen Bewegung trainiert wird.
Der Stuhl wurde entsprechend verwendet weil er gute Bearbeitung auf den Trainingsdaten verspricht.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{gfx/flownet_flying_chairs.png}
    \label{fig:flownet_flying_chairs}
    \caption{Die ersten beiden Bilder sind ein Auszug aus dem \name{Flying Chair dataset}. Das zweite Bild versetzt die Stühle ein wenig, wobei die Bewegung welche in der Kontrolle des Programmierers liegt entsprechend als Wert für das Training festgehalten wird. Im dritten Bild sieht man entsprechend die Vektoren welche als wahre Werte gehalten werden. Die Farben zeigen hierbei die Richtugn des Vektors und die Sättigung der Farbe gibt den Betrag an~\cite{Fischer2015}.}
\end{figure}

Als eine Entwicklung von \name{FlowNet} wurde \name{FlowNet 2.0}~\cite{Ilg2016} mit dem Ziel eine Verbesserung der Ergebnisse zu erzielen.
\name{FlowNet 2.0} hat einige Verbesserung im Umgang mit den Trainingsdaten eingeführt.
Diese Verbesserungen basieren auf den gefundenen Mängeln des ersten Ansatzes, welcher auf Daten der echten Welt keine Verbesserung zur bis dahin genutzten Methoden hatte\footnote{\name{FlowNet} hat allerdings gezeigt, dass maschinelles Lernen dieses Problem bearbeiten kann.}.
Zum einen wird hier ein größerer Fokus auf kleinere Änderungen in der Bewegung gelegt, was zu einer höheren Genauigkeit bei echten Bildern zur Folge hat.
Es zeigte sich außerdem, dass der Zeitplan mit welchem die Trainingsdaten an das Netzwerk geliefert werden Einfluss auf dessen Generalisierbarkeit hat.

\section{Betrachtung der Ergebnisse}

Die Bestimmung des optischen Flusses war zunächst die zugrundeliegende Überlegung zur Lösung dieser Arbeit.
Das Bild, welches diese Arbeit initial inspieriert hat ist Abbildung~\ref{fig:ai_modern_approach_optical_flow}.
Es hat sich jedoch schnell gezeigt, dass es sehr schwierig sein könnte die Ungenauigkeiten der Vektorfelder unter Kontrolle zu bringen.
Ansätze des maschinellen Lernens sind vielversprechend.
Die Entwicklung dieser zeigt, dass die in dieser Arbeit untersuchten Algorithmen durch die Nutzung der Methoden durch diese durchaus verbessert werden können und schlussendlich die Genauigkeit erhöhen können.
Zur Zeit der Bearbeitung bedarf jedoch der Mehraufwand einer Implementierung solcher Ansätze einen zu hohen Aufwand.
Um den Rahmen dieser Arbeit nicht zu übersteigen finden diese hier keine Anwendung.

\begin{figure}
    \centering
    \includegraphics[width=0.45\textwidth]{gfx/flownet_vs_flownet2.png}
    \label{fig:flownet_vs_flownet2}
    \caption{Vergleich der Genauigkeit von \name{FlowNet} gegenüber \name{FlowNet 2.0}. Die hier sichtbar verbesserte Genauigkeit ist laut den Autoren vier mal höher als beim Vorgänger~\cite{Ilg2016}}
\end{figure}

Die Implementation des Algorithmus nach Lucas-Kanade scheint jedoch eine stabile Methode zu sein Bewegung einzelner Punkte zu verfolgen.
Dieser findet vorallem im nachfolgenden Kapitel Anwendung.
